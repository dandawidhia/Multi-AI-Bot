import streamlit as st
import os
import time
from langchain.chains.combine_documents import create_stuff_documents_chain
from langchain_core.prompts import ChatPromptTemplate
from langchain_groq import ChatGroq
from dotenv import load_dotenv
import re

# Load environment variables
load_dotenv()
groq_api_key = os.getenv("GROQ_API_KEY")

# Model mapping dictionary
MODEL_MAPPING = {
    "DeepSeek R1": "deepseek-r1-distill-llama-70b",
    "Llama 8B": "llama3-8b-8192",
    "Llama 70B": "llama3-70b-8192",
    "Gemini": "gemma2-9b-it",
    "Mixtral": "mixtral-8x7b-32768"
}

# Model descriptions
MODEL_DESCRIPTIONS = {
    "DeepSeek R1": "DeepSeek R1 is a powerful LLaMA-based model optimized for efficiency and high-quality responses.",
    "Llama 8B": "Llama 8B is a mid-sized model providing balanced performance and accuracy for various AI applications.",
    "Llama 70B": "Llama 70B is an advanced model with enhanced capabilities for reasoning and detailed answers.",
    "Gemini": "Gemini (Gemma2-9B) is a fine-tuned model designed for high-quality conversational AI.",
    "Mixtral": "Mixtral 8x7B is a mixture of experts model providing exceptional performance on large-scale tasks."
}

# Streamlit Page Configuration
st.set_page_config(page_title="All in One Chatbot", layout="centered")

# Sidebar Configuration
with st.sidebar:
    st.title("Chatbot Settings")

    selected_model = st.selectbox("Select Model", list(MODEL_MAPPING.keys()))
    model_name = MODEL_MAPPING[selected_model]
    
    temperature = st.slider("Temperature", 0.0, 1.0, 0.7)
    max_tokens = st.slider("Max Tokens", 100, 4096, 1024)
    top_p = st.slider("Top-P", 0.0, 1.0, 1.0)
    frequency_penalty = st.slider("Frequency Penalty", 0.0, 1.0, 0.0)
    
    if st.button("Clear Chat"):
        st.session_state.messages = [
            {"role": "assistant", "content": f"Hi, I'm All in One ChatModel! I use different AI models. You've selected **{selected_model}**."}
        ]
        st.rerun()

# Initialize chat history
if "messages" not in st.session_state:
    st.session_state.messages = [
        {"role": "assistant", 
         "content": f"Hi, I'm All in One ChatAPP! I use different AI models. You've selected **{selected_model}**.",
        }
    ]


# Display chat history with formatted response
for message in st.session_state.messages:
    avatar = "üë§" if message["role"] == "user" else "ü§ñ"
    with st.chat_message(message["role"], avatar=avatar):
        st.markdown(message["content"], unsafe_allow_html=True)
        if message["role"] == "assistant" and "caption" in message:
            st.caption(message["caption"])

# Define prompt template
prompt_template = ChatPromptTemplate.from_template(
    """
    You are {model_name}, a powerful AI model. 
    {model_description}
    
    Answer the question to the best of your ability, even if no additional context is provided.
    Provide the most accurate response based on the question.
    
    <context>
    {context}
    </context>
    
    Question: {input}
    """
)

# Chat input field
if user_prompt := st.chat_input("How can I help you?"):
    
    # Add user message to session state
    st.session_state.messages.append({"role": "user", "content": user_prompt})
    with st.chat_message("user", avatar="üë§"):
        st.markdown(user_prompt)
    
    try:
        llm = ChatGroq(
            groq_api_key=groq_api_key, 
            model_name=model_name,
            temperature=temperature,
            max_tokens=max_tokens,
            top_p=top_p,
            frequency_penalty=frequency_penalty
        )

        document_chain = create_stuff_documents_chain(llm, prompt_template)
        
        start = time.process_time()
        response = document_chain.invoke({
            "input": user_prompt,
            "model_name": selected_model,
            "model_description": MODEL_DESCRIPTIONS[selected_model],
            "context": "",
        })
        elapsed_time = time.process_time() - start
        
        bot_response = response

        print(bot_response)
        
        # Store assistant response in session state
        st.session_state.messages.append({
            "role": "assistant", 
            "content": bot_response,
            "caption": f"üü° *Response generated by {selected_model}* ‚Äì ‚è≥ {elapsed_time:.2f} sec"
        })
        with st.chat_message("assistant", avatar="ü§ñ"):
            st.markdown(bot_response, unsafe_allow_html=True)
            st.caption(f"üü° *Response generated by {selected_model}* ‚Äì ‚è≥ {elapsed_time:.2f} sec")

    except Exception as e:
        st.error(f"‚ö†Ô∏è Error generating response: {str(e)}")

        